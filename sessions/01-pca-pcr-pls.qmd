---
title: "Learning Session 1: PCA, PCR, and PLS"
authors: "Aeka Tomita '26, Gahan Sabbir 'XX, Guilherme Fahur Bottino"
format:
  html:
    toc: true
    toc-depth: 2
    code-fold: true
    number-sections: true
execute:
  echo: true
  warning: false
  message: false
---

# Introduction

This is the first session of our **Lab Learning Sessions** series.  
We’ll explore three related but different approaches:

- **PCA (Principal Component Analysis)**
- **PCR (Principal Component Regression)**
- **PLS (Partial Least Squares)**

All methods use the same data matrix, but optimize different goals.  

## Learning Outcomes

- Understand the objectives and math of PCA, PCR, and PLS.  
- Run each method on a toy dataset.  
- Visualize and compare results.  

---

# Preparing the environment

This notebook depends on a few R packages for plotting and linear algebra operations.
THe packages should have been installed during the initial rendering, but if not, 
_run this code (only once!) to install the dependencies._

```{r}
#| code-fold: true
#| code-summary: "Show dependency codeblock"
#| echo: true
options(repos = c(CRAN = "https://cloud.r-project.org"))
packages <- c("pls", "ggplot2", "gridExtra")
to_install <- packages[!packages %in% installed.packages()[,"Package"]]
if(length(to_install)) install.packages(to_install)
invisible(lapply(packages, function(pkg) {
  suppressPackageStartupMessages(library(pkg, character.only = TRUE))
}))
```

# Motivation

For this session, we’ll work with a toy dataset that mimics measurements from a pediatric integrated-omics study.

Each row represents a different child, and the columns combine microbiome diversity metrics with biomarkers of iron metabolism, along with a clinical outcome score.

Columns:

- **MGX_Shannon_Index**
    Shannon diversity index estimated from metagenomic (MGX) profiles of the gut microbiome.
    Higher values → more diverse microbial community.
- **MGX_InvSimpson_Index**
    Inverse Simpson diversity index from the same metagenomic profiles.
    Like Shannon, but more sensitive to dominant species.
- **MBX_FreeIron**
    A simulated measure of free iron availability in the microbiome environment (MBX).
    Higher values suggest more free iron accessible to microbes.
- **MBX_Ferritin**
    A proxy for ferritin-bound iron in the system.
    Represents stored iron, less directly available to microbes.
- **AnemiaRiskScore**
    A synthetic clinical score reflecting risk of anemia (e.g., derived from hemoglobin, transferrin saturation, etc.).
    Higher values = higher risk.

# Data

First, let's assemble tha original data, as it would be utilized as a starting point:
```{r}
#| code-fold: false
dat <- data.frame(
    "MGX_Shannon_Index"     = c(2.5, 0.5, 2.2, 1.9, 3.1, 2.3, 2.0, 1.0),
    "MGX_InvSimpson_Index"  = c(2.4, 0.7, 2.9, 2.2, 3.0, 2.7, 1.6, 1.1),
    "MBX_FreeIron"          = c(0.5, 1.5, 0.3, 0.8, 0.4, 0.7, 1.2, 1.3),
    "MBX_Ferritin"          = c(1.0, 0.5, 1.2, 1.3, 1.0, 0.9, 1.5, 0.6),
    "AnemiaRiskScore"       = c(10.2,5.4,11.0, 9.1,12.5,10.4, 8.5, 6.0)
)
dat
```

It's crucial to differentiate and separate the **exposures** (input variables) and the **outcomes** (response variables) since the beginning, so let's do that before we talk about analysis.

::: callout-tip
It is common to use capital letters (`A`, `X`) to denote data matrices (2D data) and small letters (`b`, `y`) to denote data vectors (1D)
:::

```{r}
#| code-fold: false
X <- dat[, c("MGX_Shannon_Index", "MGX_InvSimpson_Index", "MBX_FreeIron", "MBX_Ferritin")]
y <- dat[, "AnemiaRiskScore"]
```

---

# Principal Component Analysis (PCA)

Wishlist:

1. Small intro with or withut equations (use LaTeX-type notations)
2. Methods to compute the Principal components
3. SVD decomposition of the X matrix (remember to mean-center and scale)
4. Explanation of each term in the SVD decomposition
5. Scree plot with the varexpl by each prin. comp. (cumulative)
6. Explanation of Loadings (Vt) and scatterplot Loadings of every variable on PC1 and PC2
7. Explanation of Scores (U) and scatterplot of samples on PC1 vs PC2 _colored by the response (y)_
8. Compare the original matrix by the reconstruction created by using 1, 2, 3 and 4 pr. comps.

# Principal Component Regression (PCR)

Wishlist:

1. Small intro of PCR. PCR first computes PCs of **X**, then regresses **y** on those PCs.  
2. It's a **supervised** step performed after the **unsupervised** PCA.
3. At some point, `pcr_model <- pcr(y ~ X1+X2+X3+X4, data = dat, scale = TRUE, validation = "LOO"); summary(pcr_model)`

# Partial Least Squares (PLS)

Wishlist:

1. Intro. Talk abotut how PLS constructs latent variables that maximize covariance with **y**.
2. It's **supervised from the start**: the response is used since the beginning, to build the components.
3. At some point, `pls_model <- plsr(y ~ X1+X2+X3+X4, data = dat, scale = TRUE, validation = "LOO"); summary(pls_model)`
4. Show that PLS has loadings on the LVs as well
5. `pls_loadings <- data.frame(pls_model$loading.weights[,1:2], var = rownames(pls_model$loading.weights))`
6. Compare the PLS loadings to the PCA loadings (here is the money shot - you will show how the generated reduced dimensions are differente)

# Comparing predictions by PCR and PLS

**PCR → PCs ordered by variance in X**

**PLS → LVs ordered by covariance with y**

```
pcr_pred <- predict(pcr_model, ncomp = 1)
pls_pred <- predict(pls_model, ncomp = 1)
## Idea: let's vary the number of `ncomp` and see if they converge!

pred_df <- data.frame(
  y = y,
  PCR = as.numeric(pcr_pred),
  PLS = as.numeric(pls_pred)
)

library(gridExtra)
p3 <- ggplot(pred_df, aes(x = y)) +
  geom_point(aes(y = PCR), color = "blue", size = 3, shape = 16) +
  geom_point(aes(y = PLS), color = "red", size = 3, shape = 17) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed") +
  ylab("Predicted") + ggtitle("PCR vs PLS (1 component)")
p3
```

---

# Summary Table

| Aspect              | PCA / PCR     | PLS           |
|---------------------|---------------|---------------|
| Objective           |               |               |
| Reduced Components  |               |               |
| Uses **y**?         |               |               |
| Use case + Advice   |               |               |
---

# Wrap-up

- **PCA**: Unsupervised variance reduction of a dataset.
- **PCR**: Supervised post-PCA - regresses on PCs.
- **PLS**: Supervised, reduced components aligned with y.

**Take-home message:**  
_Insert a take-home message here_
